#!/usr/bin/env python3
import json
import logging
import pathlib
import sqlite3
import subprocess
import time
from typing import Any

import click
import docker

import results_db

SCRIPT_PATH = pathlib.Path(__file__).parent


DockerImageType = str


class ContainerManager:
    """Wraps container runtime interface API to simplifiy
    run, terminate, retrieve logs and test environment data
    """

    def __init__(self, cri: docker.DockerClient, image: DockerImageType):
        self.cri = cri
        self.image = self.cri.images.pull(image)
        logging.debug("Pulled %s", self.image)

    def run(self, **kwargs) -> docker.models.containers.Container:
        """wrap docker client run(). runs detached and set
        self.container to the started container. forward args"""

        self.container = self.cri.containers.run(self.image.id, detach=True, **kwargs)
        logging.debug(
            "Started container for image %s: %s", self.image, self.container.name
        )
        return self.container

    def run_once(self, **kwargs) -> str:
        "wrap docker client run(). like subprocess.check_output()"
        return self.cri.containers.run(self.image.id, **kwargs)

    def terminate(self):
        "terminate container started with run()"
        res = self.container.stop(timeout=30)
        logging.info("Terminating container %s: %s", self.container, res)

    def logs(self, **kwargs) -> bytes:
        "get logs of container started with run()"
        return self.container.logs(**kwargs)

    def env(self) -> results_db.TestEnvType:
        "get test environment data"
        return {
            "image-id": self.image.id,
            "image-tags": ";".join(self.image.tags),
        }


class S3GW(ContainerManager):
    def __init__(
        self, cri: docker.DockerClient, image: DockerImageType, storage: "Storage"
    ):
        self.storage = storage
        self.s3gw_version = "unknown"
        super().__init__(cri, image)

    def run(self, **args):
        self.container = self.cri.containers.run(
            self.image.id,
            detach=True,
            **args,
            network_mode="host",
            volumes={
                self.storage.mountpoint: {
                    "bind": "/data",
                    "mode": "rw",
                }
            },
        )
        ret, version = self.container.exec_run(["radosgw", "--version"])
        if ret == 0:
            self.s3gw_version = version

        logging.info("üîé S3GW container: %s", self.container.name)
        return self.container

    def env(self):
        e = super().env()
        e["s3gw-version"] = self.s3gw_version
        return e


class Storage:
    "A storage device to run the program under test on"

    def __init__(
        self,
        enable_reset_mkfs_mount: bool,
        device: pathlib.Path,
        partition: pathlib.Path,
        mountpoint: pathlib.Path,
        mkfs_command: list[str],
    ):
        self.enable_reset_mkfs_mount = enable_reset_mkfs_mount
        self.mountpoint = mountpoint
        self.device = device
        self.partition = partition
        self.mkfs_command = mkfs_command

        logging.info(
            "Storage device: %s, mountpoint %s, partition: %s",
            self.device,
            self.mountpoint,
            self.partition,
        )

        out = subprocess.check_output(
            [
                "lsblk",
                "--output",
                "NAME,TYPE,MODEL,VENDOR,FSTYPE,FSSIZE,PHY-SEC,REV,ROTA,SCHED,RQ-SIZE",
                "--json",
                str(self.device),
            ]
        )
        d = json.loads(out)["blockdevices"][0]
        logging.info("Device: %s", d)
        self.env_data = {
            "disk-dev-name": d["name"],
            "disk-model": d["model"],
            "disk-vendor": d["vendor"],
            "disk-rotational": d["rota"],
            "disk-scheduler": d["sched"],
            "disk-physical-sector-size": d["phy-sec"],
        }

    def reset(self):
        if not self.enable_reset_mkfs_mount:
            logging.info("üõ¢ storage reset disabled. skipping umount, mkfs, mount")
            return
        try:
            logging.info(
                f"üõ¢ resetting storage: mountpoint {self.mountpoint}, "
                f"dev {self.partition}, command {self.mkfs_command}"
            )
            try:
                umount_out = subprocess.check_output(
                    ["sudo", "umount", str(self.mountpoint.absolute())],
                    stderr=subprocess.STDOUT,
                )
                logging.debug("umount: %s", umount_out)
            except subprocess.CalledProcessError as e:
                # on first run mountpoint is typically not mounted
                if b"not mounted" not in e.output:
                    raise e

            time.sleep(1)
            mkfs_out = subprocess.check_output(
                self.mkfs_command + [str(self.partition)], stderr=subprocess.STDOUT
            )
            logging.debug("mkfs out: %s", mkfs_out)

            mount_out = subprocess.check_output(
                ["sudo", "mount", str(self.partition), str(self.mountpoint.absolute())],
                stderr=subprocess.STDOUT,
            )
            logging.debug("mount out: %s", mount_out)

            chown_out = subprocess.check_output(
                ["sudo", "chown", "vogon:vogon", self.mountpoint],
                stderr=subprocess.STDOUT,
            )
            logging.debug("chown out: %s", chown_out)

        except subprocess.CalledProcessError as e:
            logging.exception(
                "storage reset (umount,mkfs,mount) failed with exit %s out %s. "
                "failing benchmark",
                e.returncode,
                e.output,
            )
            raise e

    def env(self):
        return self.env_data

    def drop_caches(self):
        "Drop caches. Classic echo 3 > /proc/sys/vm/drop_caches"
        # raises exception if fails
        try:
            subprocess.check_call(
                ["sudo", "bash", "-c", "echo 3 > /proc/sys/vm/drop_caches"]
            )
        except subprocess.CalledProcessError as e:
            logging.exception("os cached drop failed. failing benchmark")
            raise e


ResultList = [(str, Any, str)]


class Test:
    def __init__(self, name: str):
        self.name = name

    def env(self, instance: "TestRunner") -> results_db.TestEnvType:
        "Return environment data. e.g test tool version"
        raise NotImplementedError

    def results(self, instance: "TestRunner") -> results_db.TestResultsType:
        "Return test run results"
        raise NotImplementedError

    def run(self, instance: "TestRunner") -> int:
        "Run test to completion"
        raise NotImplementedError

    def kind(self) -> str:
        raise NotImplementedError


class AbortTest(Exception):
    pass


class ContainerizedTest(Test):
    def __init__(self, name: str, container_image: DockerImageType):
        self.container_image = container_image
        super().__init__(name)

    def run(self, instance: "TestRunner"):
        container_manager = ContainerManager(instance.cri, self.container_image)
        return container_manager.run()

    def env(self, instance: "TestRunner"):
        raise NotImplementedError

    def results(self, instance: "TestRunner"):
        raise NotImplementedError

    def kind(self) -> str:
        raise NotImplementedError


class HostTest(Test):
    def __init__(self, name):
        super().__init__(name)

    def run(self, instance: "TestRunner"):
        raise NotImplementedError

    def env(self, instance: "TestRunner"):
        raise NotImplementedError

    def results(self, instance: "TestRunner") -> results_db.TestResultsType:
        raise NotImplementedError

    def kind(self) -> str:
        raise NotImplementedError


class FIOTest(HostTest):
    def __init__(self, name: str, job_file: pathlib.Path):
        self.job_file = job_file
        super().__init__(name)

    def run(self, instance: "TestRunner"):
        try:
            logging.info(
                "running fio with job file %s in %s",
                self.job_file,
                instance.storage.mountpoint,
            )
            out = subprocess.check_output(
                ["fio", "--output-format=json", str(self.job_file.absolute())],
                stderr=subprocess.STDOUT,
                cwd=instance.storage.mountpoint,
            )
        except subprocess.CalledProcessError:
            logging.exception("fio crashed :()", exc_info=True)
            return -1

        self.json = out
        self.data = json.loads(out)

        return 0

    def env(self, instance: "TestRunner"):
        return {"fio-version": self.data["fio version"]}

    def results(self, instance: "TestRunner"):
        j = self.data["jobs"][0]
        return [
            ("JSON", self.json, "JSON"),
            ("read-iops", j["read"]["iops"], "iops"),
            ("read-bw", j["read"]["bw_bytes"], "byte"),
            ("write-iops", j["read"]["iops"], "iops"),
            ("write-bw", j["read"]["bw_bytes"], "byte"),
        ]

    def kind(self) -> str:
        return "FIO"

    def __str__(self) -> str:
        return f"FIO(job_file={self.job_file})"


class WarpTest(ContainerizedTest):
    default_container_image = "minio/warp"
    default_args = ["--no-color"]
    default_workload_args = [
        "--host=localhost:7480",
        "--access-key=test",
        "--secret-key=test",
        "--benchdata=/warp.out",
    ]

    def __init__(self, name: str, workload: str, args: list[str] = []):
        super().__init__(name, self.default_container_image)
        self.workload = workload
        self.args = args
        self.raw_results: str = ""
        self.json_results: dict = {}

    def run(self, instance: "TestRunner"):
        self.container = ContainerManager(instance.cri, self.container_image)
        self.warp_version = self.container.run_once(command="--version")
        args = []
        args.extend(self.default_args)
        args.append(self.workload)
        args.extend(self.default_workload_args)
        args.extend(self.args)

        running = self.container.run(
            command=args, network_mode="host", name=f"warp_{instance.rep_id}"
        )
        logging.info("üîé Warp container: %s", running.name)

        result = running.wait()
        self.last_run = running

        try:
            bits, stat = self.last_run.get_archive("/warp.out.csv.zst")
            with open(
                instance.archive / (instance.rep_id + "_warp.out.csv.zst"), "wb"
            ) as fd:
                for chunk in bits:
                    fd.write(chunk)
        except docker.errors.NotFound:
            logging.error("warp results file not found. ignoring")

        self.last_run_image = self.last_run.commit(
            f"localhost/{self.default_container_image}", f"test_rep_{instance.rep_id}"
        )
        logging.info("üîé Commited warp run container to %s", self.last_run_image)

        data = instance.cri.containers.run(
            self.last_run_image,
            remove=True,
            stdout=True,
            stderr=True,
            tty=True,
            command=["analyze", "--json", "/warp.out.csv.zst"],
        )
        try:
            data = data.decode("utf-8")
        except (UnicodeDecodeError, AttributeError):
            pass

        self.raw_results = data
        self.json_results = self.parse_warp_json(data)

        return result["StatusCode"]

    def parse_warp_json(self, data: str) -> dict:
        try:
            json_start = data.find("{")
            json_stop = data.rfind("}")
            jdata = data[json_start : json_stop + 1]
            return json.loads(jdata)
        except json.decoder.JSONDecodeError:
            logging.error("warp result parsing failed.", exc_info=True)
            logging.error("data:\n %s", jdata, exc_info=True)
            return {}

    def results(self, instance: "TestRunner"):
        results = []
        if not self.last_run:
            return None

        results.append(("JSON", self.raw_results, "JSON"))

        for op in self.json_results.get("operations", []):
            prefix = op["type"] + "_"
            results.append(
                (prefix + "avg-ops", op["throughput"]["average_ops"], "ops/s")
            )
            results.append(
                (prefix + "avg-bps", op["throughput"]["average_bps"], "byte/s")
            )
            results.append((prefix + "ops", op["throughput"]["operations"], "ops"))

        return results

    def env(self, instance: "TestRunner"):
        env = self.container.env()
        env["warp-version"] = self.warp_version
        return env

    def kind(self) -> str:
        return "WARP"

    def __str__(self) -> str:
        args_str = ",".join(self.args)
        return f"Warp(workload={self.workload}, args={args_str})"


class TestSuite:
    def __init__(self, name: str, description: str, tests: list[Test]):
        self.name = name
        self.description = description
        self.tests = tests


class TestRunner:
    def __init__(
        self,
        cri: docker.DockerClient,
        db: results_db.ResultsDB,
        under_test_container: ContainerManager,
        storage: Storage,
        archive: pathlib.Path,
        reps: int,
    ):
        self.cri = cri
        self.db = db
        self.under_test_container = under_test_container
        self.storage = storage
        self.archive = archive
        self.reps = reps

        self.under_test_container_env_saved = False

        self.suite_id = "NA"
        self.test_id = "NA"
        self.rep_id = "NA"

    def __str__(self):
        return f"TestSuite(name={self.suite_name}, suite_id={self.suite_id})"

    def run_suite(self, suite):
        self.suite_id = results_db.make_id()
        logging.info(f"‚ñ∂Ô∏è STARTING TEST SUITE {suite.name} ID {self.suite_id}")
        logging.info(f"‚ôªÔ∏è {self.reps} REPS / TEST")
        self.db.save_before_suite(self.suite_id, suite.name, suite.description)
        self.db.save_test_environment_default(self.suite_id)
        self.db.save_test_environment(self.suite_id, self.storage.env())

        for test in suite.tests:
            self.run_test(test)

        self.db.save_after_suite(self.suite_id)

    def run_test(self, test: Test):
        self.test_id = results_db.make_id()

        self.db.save_before_test(self.suite_id, self.test_id, str(test), test.kind())
        logging.info(f"üîé TEST {test} ID {self.test_id}")

        for rep in range(self.reps):
            logging.info("‚ñ∂Ô∏è %s REP %s/%s", test.name, rep, self.reps)
            try:
                self.run_test_rep(test)
            except Exception:
                logging.exception(
                    "üò• TEST %s REP %s/%s FAILED. Continuing with next test in suite",
                    test,
                    rep,
                    self.reps,
                    exc_info=True,
                )
                return

        self.db.save_after_test(self.test_id)
        self.db.save_test_environment(self.suite_id, test.env(self), test.name + "-")

    def run_test_rep(self, test: Test):
        self.rep_id = results_db.make_id()
        self.db.save_before_rep(self.test_id, self.rep_id)
        self.storage.reset()

        logging.info("üîéÔ∏è TEST %s REP ID %s", test.name, self.rep_id)
        self.under_test_container.run(name=f"under_test_{self.rep_id}")
        self.save_under_test_container_env_once()

        # TODO be smarter about the started condition
        time.sleep(10)

        self.storage.drop_caches()
        try:
            returncode = test.run(self)
        except Exception as e:
            logging.exception(
                "üò• TEST %s REP ID %s failed with exception: %s",
                test.name,
                self.rep_id,
                e,
                exc_info=True,
            )

            self.db.save_after_rep(self.rep_id, -10, f"failed with exception: {str(e)}")
            raise e

        if returncode != 0:
            logging.error(
                "üò• TEST %s REP ID %s finished with returncode != 0: %s",
                test.name,
                self.rep_id,
                returncode,
            )
            self.db.save_after_rep(
                self.rep_id, returncode, "failed with non-zero return code"
            )
            raise AbortTest

        try:
            results = test.results(self)
        except Exception as e:
            logging.exception(
                "üò• TEST %s REP ID %s" " result parsing failed with exception: %s",
                test.name,
                self.rep_id,
                e,
                exc_info=True,
            )
            self.db.save_after_rep(
                self.rep_id, -20, f"result parser returned exception: {str(e)}"
            )
            raise e

        self.db.save_after_rep(self.rep_id, returncode, "successful")
        self.db.save_test_results(self.rep_id, results)

        self.under_test_container.terminate()

    def save_under_test_container_env_once(self):
        # call this after first run() - under test container usually
        # has env data avail afterwards
        if self.under_test_container_env_saved:
            return
        self.db.save_test_environment(
            self.suite_id, self.under_test_container.env(), "under-test-"
        )


warp_mixed_default = WarpTest("mixed-default", "mixed")
warp_get_default = WarpTest("get-default", "get")
warp_put_default = WarpTest("put-default", "put")
warp_list_default = WarpTest("list-default", "list")
warp_delete_default = WarpTest("delete-default", "delete")
warp_stat_default = WarpTest("stat-default", "stat")

fio_sfs_like = FIOTest("fio-sfs-like", SCRIPT_PATH / "fio" / "sfs-like_10M-files.fio")

test_suites = [
    TestSuite(
        "baseline",
        "Test disk baseline performance",
        tests=[
            fio_sfs_like,
        ],
    ),
    TestSuite(
        "demo",
        "Fast demo test suite",
        tests=[
            WarpTest(
                "mixed-fast",
                "mixed",
                ["--duration=10s", "--objects=10", "--concurrent=1"],
            ),
            WarpTest(
                "get-fast", "get", ["--duration=10s", "--objects=10", "--concurrent=1"]
            ),
            WarpTest("put-fast", "put", ["--duration=10s", "--concurrent=1"]),
            WarpTest(
                "list-fast",
                "list",
                ["--duration=10s", "--objects=10", "--concurrent=1"],
            ),
            WarpTest(
                "delete-fast",
                "delete",
                ["--duration=10s", "--objects=10", "--batch=1", "--concurrent=1"],
            ),
            WarpTest(
                "stat-fast",
                "stat",
                ["--duration=10s", "--objects=10", "--concurrent=1"],
            ),
        ],
    ),
    TestSuite(
        "s3-simple-micro",
        "S3 micro benchmarks. Simple operations (GET, PUT, DELETE, list, etc.).",
        tests=[
            warp_mixed_default,
            warp_get_default,
            warp_put_default,
            warp_list_default,
            warp_delete_default,
            warp_stat_default,
        ],
    ),
]

test_suites_indexed = {suite.name: suite for suite in test_suites}


@click.group()
@click.option("--debug/--no-debug", default=False)
@click.pass_context
def cli(ctx, debug):
    ctx.ensure_object(dict)
    loglevel = [logging.WARNING, logging.DEBUG][int(debug)]
    logging.basicConfig(
        level=loglevel, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    ctx.obj["DEBUG"] = debug
    logging.getLogger("urllib3.connectionpool").setLevel(logging.WARN)
    logging.getLogger("docker.auth").setLevel(logging.INFO)
    logging.getLogger("docker.utils.config").setLevel(logging.INFO)


@cli.command()
@click.pass_context
@click.option(
    "--under-test-image",
    type=str,
    required=True,
    help="Docker image of the application under test",
)
@click.option(
    "--suite",
    type=click.Choice(list(test_suites_indexed.keys())),
    required=True,
    help="Test suite. See vogon2.py for configuration",
)
@click.option(
    "--archive-dir",
    type=click.Path(
        exists=True,
        file_okay=False,
        dir_okay=True,
        writable=True,
        resolve_path=True,
        allow_dash=False,
        path_type=pathlib.Path,
    ),
    required=True,
    help="Directory to archive test artifacts to",
)
@click.option(
    "--storage-device",
    type=click.Path(
        exists=True,
        file_okay=True,
        dir_okay=False,
        writable=True,
        resolve_path=True,
        allow_dash=False,
        path_type=pathlib.Path,
    ),
    required=True,
    help="Storage device to extract information from (e.g /dev/disk/by-id/...)",
)
@click.option(
    "--storage-partition",
    type=click.Path(
        exists=True,
        file_okay=True,
        dir_okay=False,
        writable=True,
        resolve_path=True,
        allow_dash=False,
        path_type=pathlib.Path,
    ),
    required=True,
    help="Storage device to run on (e.g /dev/disk/by-id/...)",
)
@click.option(
    "--mountpoint",
    type=click.Path(
        exists=True,
        file_okay=False,
        dir_okay=True,
        writable=True,
        resolve_path=True,
        allow_dash=False,
        path_type=pathlib.Path,
    ),
    required=True,
    help="Mountpoint for --storage-device",
)
@click.option(
    "--mkfs",
    type=str,
    required=True,
    help="mkfs command. splitted by .split(). append device on call",
)
@click.option(
    "--docker-api",
    type=str,
    required=True,
    help="Docker API URI. e.g unix://run/podman/podman.sock",
)
@click.option(
    "--sqlite", type=str, required=True, help="Where to find the sqlite database?"
)
@click.option("--init-db/--no-init-db", default=False, help="Create tables, etc")
@click.option(
    "--reset-storage/--no-reset-storage",
    default=False,
    help="Reset storage (umount,mkfs,mount) between reps",
)
@click.option("--repeat", type=int, default=1, help="How many repetitions to run")
def test(
    ctx,
    under_test_image,
    suite,
    archive_dir,
    storage_device,
    storage_partition,
    mountpoint,
    mkfs,
    docker_api,
    sqlite,
    init_db,
    reset_storage,
    repeat,
):
    cri = docker.DockerClient(base_url=docker_api)
    dbconn = sqlite3.connect(sqlite)
    if init_db:
        results_db.init_db(dbconn)
    cur = dbconn.cursor()
    cur.execute("PRAGMA foreign_keys = ON;")
    cur.close()

    db = results_db.ResultsDB(dbconn)
    storage = Storage(
        reset_storage, storage_device, storage_partition, mountpoint, mkfs.split()
    )
    s3gw = S3GW(cri, under_test_image, storage)
    test_runner = TestRunner(cri, db, s3gw, storage, archive_dir, repeat)
    try:
        test_runner.run_suite(test_suites_indexed[suite])
    finally:
        s3gw.terminate()
        dbconn.close()


if __name__ == "__main__":
    cli(obj={})
